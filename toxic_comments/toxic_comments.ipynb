{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-библиотек-и-данных\" data-toc-modified-id=\"Загрузка-библиотек-и-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка библиотек и данных</a></span></li><li><span><a href=\"#Ознакомление-с-данными\" data-toc-modified-id=\"Ознакомление-с-данными-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Ознакомление с данными</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выбор-способов-предобработки-данных\" data-toc-modified-id=\"Выбор-способов-предобработки-данных-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Выбор способов предобработки данных</a></span></li><li><span><a href=\"#Фильтрация-символов-и-лемматизация-токенов\" data-toc-modified-id=\"Фильтрация-символов-и-лемматизация-токенов-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Фильтрация символов и лемматизация токенов</a></span></li><li><span><a href=\"#Векторизация-текстов\" data-toc-modified-id=\"Векторизация-текстов-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Векторизация текстов</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Градиентный-бустинг-(CatBoost)\" data-toc-modified-id=\"Градиентный-бустинг-(CatBoost)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Градиентный бустинг (CatBoost)</a></span></li><li><span><a href=\"#Анализ-лучших-моделей\" data-toc-modified-id=\"Анализ-лучших-моделей-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Анализ лучших моделей</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек и данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загразука библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer as wordnet_lemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "\n",
    "try:\n",
    "    comments_data = pd.read_csv('/datasets/toxic_comments.csv', \n",
    "                                error_bad_lines=False, \n",
    "                                index_col = 0)\n",
    "\n",
    "except:\n",
    "    comments_data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', \n",
    "                                error_bad_lines=False , \n",
    "                                index_col = 0)\n",
    "    \n",
    "comments_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержат около 100 строк с ошибками форматирования, поэтому они были пропущены (параметр `error_bad_lines=False`). Доля пропущенных строк пренебрежимо мала, поэтому не должна оказать существенного влияния на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ознакомление с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим отсутствие пропусков и дубликатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text     0.0\n",
       "toxic    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дубликатов: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Доля пропусков:\")\n",
    "display(comments_data.isna().mean())\n",
    "\n",
    "print(f\"Доля дубликатов: {comments_data.duplicated().mean()*100:0.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски и дубликаты отсутствуют.  \n",
    "Проверим долю токсичных комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1016"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_data.toxic.values.mean().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка не сбалансирована относительно числа токсичных комментариев. Это обстоятельство должно быть учтено при построении модели.  \n",
    "Записи в начале и конце выборки написаны на английском языке. Для выбора адекватного подхода при предобработке рассмотрим распространенность символов в комментариях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>counts per comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>67.86015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e</td>\n",
       "      <td>36.65465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t</td>\n",
       "      <td>28.68060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>25.32435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>25.08825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>‎</td>\n",
       "      <td>0.00525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>$</td>\n",
       "      <td>0.00465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>0.00350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>á</td>\n",
       "      <td>0.00345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ü</td>\n",
       "      <td>0.00340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol  counts per comment\n",
       "1                     67.86015\n",
       "5        e            36.65465\n",
       "7        t            28.68060\n",
       "2        a            25.32435\n",
       "0        i            25.08825\n",
       "..     ...                 ...\n",
       "112      ‎             0.00525\n",
       "51       $             0.00465\n",
       "129      <             0.00350\n",
       "169      á             0.00345\n",
       "106      ü             0.00340\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars = dict()\n",
    "N_COMMENTS = 20_000\n",
    "\n",
    "for comment in comments_data.sample(N_COMMENTS, replace=False).text.values:\n",
    "    for char in comment:\n",
    "        if all_chars.get(char.lower()):\n",
    "            all_chars[char.lower()] = all_chars.get(char.lower()) + 1 / N_COMMENTS\n",
    "        else:\n",
    "            all_chars[char.lower()] = 1 / N_COMMENTS\n",
    "            \n",
    "pd.DataFrame({'symbol' : all_chars.keys(),\n",
    "             'counts per comment': all_chars.values()}).sort_values(by='counts per comment', \n",
    "                                                                    ascending=False).head(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 50 наиболее популярных символов входят только символы латинского алфавита, цифры, специальные символы и знаки пунктуации. Символы других алфавитов встречаются не чаще 3 раз на 1000 комментариев. Даже если такие символы не случайны, а комментарии действительно написаны не на английском языке, количество таких комментариев недостаточно для построения качественной модели на их основе. Таким образом, при предобработке могут быть исключены все буквенные символы кроме символов латинского алфавита."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор способов предобработки данных\n",
    "\n",
    "Требования к итоговой модели относительно низкие (F1-метрика выше 0,75), поэтому для её создания могут быть использованы классические методы машинного обучения. Предобработка в таком случае будет включать следующие этапы:\n",
    "- очистка текста от \"неправильных\" символов;\n",
    "- лемматизация/стеммизация токенов;\n",
    "- составление n-грамм;\n",
    "- векторизация текста (tf-idf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Фильтрация символов и лемматизация токенов\n",
    "Исключим числа и символы кроме символов латинского алфавита, а также приведем записи к нижнему регистру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww he matches this background colour i'm se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i'm really not trying to edit war it's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can't make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>and i really don't think you understand i came...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation why the edits made under my userna...      0\n",
       "1       d'aww he matches this background colour i'm se...      0\n",
       "2       hey man i'm really not trying to edit war it's...      0\n",
       "3       more i can't make any real suggestions on impr...      0\n",
       "4       you sir are my hero any chance you remember wh...      0\n",
       "...                                                   ...    ...\n",
       "159446  and for the second time of asking when your vi...      0\n",
       "159447  you should be ashamed of yourself that is a ho...      0\n",
       "159448  spitzer umm theres no actual article for prost...      0\n",
       "159449  and it looks like it was actually you who put ...      0\n",
       "159450  and i really don't think you understand i came...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_data.text = comments_data.text.apply(lambda x: ' '.join(re.sub(\"([^\\w\\']|[\\d])\", \" \", x).split()).lower())\n",
    "comments_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем все слова в комментариях к исходной форме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww he match this background colour i'm seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i'm really not trying to edit war it's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can't make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d'aww he match this background colour i'm seem...      0\n",
       "2  hey man i'm really not trying to edit war it's...      0\n",
       "3  more i can't make any real suggestion on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = wordnet_lemmatizer()\n",
    "\n",
    "comments_data.text = comments_data.text.apply(lambda x: \" \".join(wn.lemmatize(word) for word in x.split()))\n",
    "comments_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Векторизация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая низкие требования, удовлетворительное качество модели может быть получено за счет учета обсценной лексики и прямых оскорблений. В таком случае не требуется развитый учет контекста, поэтому будет достаточно tf-idf векторизации. Поскольку токсичность комментария зависит от его направленности (на самого говорящего (самокритика) или собеседника) использование стоп-слов в данном случае нежелательно.  \n",
    "\n",
    "Чтобы условия проверки моделей соответствовали реальности векторизация должна обучаться только на тренировочном наборе данных, поэтому заранее поделим данные на тренировочный, тестовый и валидационный наборы (учитывая большой объем данных можно обойстись проверкой на отложенной выборке, без кроссвалидации):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(comments_data, test_size=0.4, random_state = 123)\n",
    "train, val = train_test_split(train_val, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальную частоту встречаемости токенов при векторизации следует установить близкой по порядку к доле позитивного (токсичного) класса, а минимальную - порядка нескольких единиц или десятков для исключения случайных и слишком редких слов. Отдельно построим представления для униграмм, а также униграмм и биграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем два векторизатора для исключительно униграмм и униграмм и биграмм:\n",
    "vectorizer_uni = TfidfVectorizer(max_df=0.5, min_df=30, ngram_range=(1, 1))\n",
    "vectorizer_bi = TfidfVectorizer(max_df=0.5, min_df=30, ngram_range=(1, 2))\n",
    "\n",
    "for vec in [vectorizer_uni, vectorizer_bi]:\n",
    "    vec.fit(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразованные записи сохраним в списки по три:\n",
    "comments_unigramm = []\n",
    "comments_bigramm = []\n",
    "\n",
    "for part in [train, val, test]:\n",
    "    comments_unigramm.append(vectorizer_uni.transform(part.text))\n",
    "    comments_bigramm.append(vectorizer_bi.transform(part.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текстовые данные подготовлены. Можно переходить к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейные модели хорошо подходят для работы категориальными признаками (результат зависит от наличия или отсутствия определенной категории), поэтому можно ожидать неплохого результата при бинарной классификации тональности текстов. Кроме того, линейные модели обладают наибольшой скоростью работы. Проверим модель логистической регрессии на текстах кодированных при помощи униграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_uni = LogisticRegression(max_iter=300, random_state=123)\n",
    "model_lr_uni.fit(comments_unigramm[0], train.toxic)\n",
    "f1_score(val.toxic, model_lr_uni.predict(comments_unigramm[1])).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели близко к предъявленным требованиям. Поскольку данные несбалансированы, для максимизации F1-метрики можно воспользоваться подбором порога классификации. Напишем функцию для подбора порога классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_opti(model, test_t, test_f):\n",
    "    best_thresh = 0\n",
    "    score = 0\n",
    "    pred = model.predict_proba(test_f)\n",
    "    \n",
    "    for thresh in np.linspace(0, 1):\n",
    "        cur_score = f1_score(test_t, pred[:,1]>thresh)\n",
    "        if cur_score > score:\n",
    "            score = cur_score\n",
    "            best_thresh = thresh\n",
    "    print(f\"Лучшее значение F1-метрики: {score:0.3f} при пороге {best_thresh:0.3f}\")\n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим лучший порог при использовании униграмм на тренировочной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1-метрики: 0.778 при пороге 0.286\n"
     ]
    }
   ],
   "source": [
    "best_thres_lr_uni = thresh_opti(model_lr_uni, val.toxic, comments_unigramm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель с использованием представления, включающего биграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_bi = LogisticRegression(max_iter=300, random_state=123)\n",
    "model_lr_bi.fit(comments_bigramm[0], train.toxic)\n",
    "f1_score(val.toxic, model_lr_bi.predict(comments_bigramm[1])).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели, обученной на представленнии, влючающем биграммы, хуже, чем у более простой модели. Возможно это связано с трудностью отбора значимых признаков и переобучением. Попробуем улучшить результат подбором порога классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1-метрики: 0.770 при пороге 0.245\n"
     ]
    }
   ],
   "source": [
    "best_thres_lr_bi = thresh_opti(model_lr_bi, val.toxic, comments_bigramm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика снова оказалась хуже чем для более простой модели. Следовательно предпочтение следует отдать более простой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг (CatBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим более сложную модель - градиентный бустинг. Для снижения риска переобучения и ускорения обучения модели ограничим число итераций, а чтобы учесть дисбаланс классов, установим параметр 'auto_class_weights' равным 'Balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.125045\n",
      "0:\tlearn: 0.6538862\ttest: 0.6682767\tbest: 0.6682767 (0)\ttotal: 1.81s\tremaining: 15m 5s\n",
      "100:\tlearn: 0.8764789\ttest: 0.8647282\tbest: 0.8651693 (99)\ttotal: 2m 6s\tremaining: 8m 20s\n",
      "200:\tlearn: 0.9108431\ttest: 0.8785633\tbest: 0.8786710 (197)\ttotal: 4m\tremaining: 5m 57s\n",
      "300:\tlearn: 0.9291811\ttest: 0.8818204\tbest: 0.8827146 (256)\ttotal: 5m 53s\tremaining: 3m 53s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8827146475\n",
      "bestIteration = 256\n",
      "\n",
      "Shrink model to first 257 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.713"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb = CatBoostClassifier(iterations=500, \n",
    "                              verbose=100,\n",
    "                              eval_metric='F1',\n",
    "                              early_stopping_rounds=50,\n",
    "                              auto_class_weights='Balanced',\n",
    "                              random_seed=123)\n",
    "\n",
    "model_gb.fit(comments_unigramm[0],\n",
    "             train.toxic,\n",
    "             eval_set=(comments_unigramm[1], val.toxic))\n",
    "\n",
    "f1_score(val.toxic, model_gb.predict(comments_unigramm[1])).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить целевую метрику подбором порога классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1-метрики: 0.766 при пороге 0.653\n"
     ]
    }
   ],
   "source": [
    "best_thres_gb_uni = thresh_opti(model_gb, val.toxic, comments_unigramm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики хуже, чем для модели логистической регрессии, при значительно большем времени обучения и предсказания.  \n",
    "`CatBoost` отличается от прочих наличием встроенной поддержки текстовых признаков, для построения биграмм воспользуемся встроенными возможностям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.125045\n",
      "0:\tlearn: 0.8369804\ttest: 0.8475891\tbest: 0.8475891 (0)\ttotal: 420ms\tremaining: 3m 29s\n",
      "100:\tlearn: 0.8952252\ttest: 0.9000996\tbest: 0.9000996 (100)\ttotal: 40.8s\tremaining: 2m 41s\n",
      "200:\tlearn: 0.9123847\ttest: 0.9029208\tbest: 0.9032351 (198)\ttotal: 1m 20s\tremaining: 2m\n",
      "300:\tlearn: 0.9236196\ttest: 0.9047701\tbest: 0.9053888 (293)\ttotal: 2m\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9053888248\n",
      "bestIteration = 293\n",
      "\n",
      "Shrink model to first 294 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.718"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(iterations=500, \n",
    "                               verbose=100,\n",
    "                               text_features=['text'],\n",
    "                               eval_metric='F1',\n",
    "                               early_stopping_rounds=50,\n",
    "                               auto_class_weights='Balanced',\n",
    "                               dictionaries=[{\"dictionary_id\" : \"BiGram\",\n",
    "                                              \"gram_order\" : \"2\"\n",
    "                                             }, \n",
    "                                             {\"dictionary_id\" : \"Word\",\n",
    "                                              \"gram_order\" : \"1\"\n",
    "                                             }],\n",
    "                               random_seed=123)\n",
    "\n",
    "model_cat.fit(train.drop('toxic', axis=1), \n",
    "              train.toxic, \n",
    "              eval_set=(val.drop('toxic', axis=1), val.toxic))\n",
    "\n",
    "f1_score(val.toxic, model_cat.predict(val.drop('toxic', axis=1))).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время обучения модели существенно сократилось в сравнении с использовнием внешней векторизации текста. F1-метрика модели оказалась снова хуже полученной для логистической регрессии. Определим порог классификации, максимизирующий целевую метрику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1-метрики: 0.789 при пороге 0.796\n"
     ]
    }
   ],
   "source": [
    "best_thres_cat_bi = thresh_opti(model_cat, val.toxic, val.drop('toxic', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После подбора порога классификации значение целевой метрики превысило значение метрики для логистической регрессии. Учитывая очень небольшую разницу в F1-метрике, для выбора лучшей модели дополнительно сравним точность моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность при оптимальном для F1-метрики пороге:\n",
      ".......... 0.9567 - логистическая регрессия\n",
      ".......... 0.9575 - градиентный бустинг (CatBoost)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_lr = accuracy_score(val.toxic, \n",
    "                             model_lr_uni.predict_proba(comments_unigramm[1])[:,1]>best_thres_lr_uni)\n",
    "\n",
    "accuracy_cat_bi = accuracy_score(val.toxic, \n",
    "                             model_cat.predict_proba(val.drop('toxic', axis=1))[:,1]>best_thres_cat_bi)\n",
    "\n",
    "print(\"Точность при оптимальном для F1-метрики пороге:\")\n",
    "print(10*'.', f\"{accuracy_lr:0.4f} - логистическая регрессия\")\n",
    "print(10*'.', f\"{accuracy_cat_bi:0.4f} - градиентный бустинг (CatBoost)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность модели градиентного бустинга превышает точность логистической регрессии менее чем на 0.001. \n",
    "Учитывая разную сложность моделей, разное время их обучения и разное время предсказания, в данном случае предпочтение следует отдать более простой модели - логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ лучших моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как было написано выше, в данном случае, при использовании tf-idf векторизации лучшей моделью является модель логистической регрессии. Объяснением хорошей работы линейной модели в данном проекте является то, что модель фактически работает с качественными признаками - наличием или отсутствием определенных \"токсичных\" слов в комментарии. \n",
    "Качество предсказаний градиентного бустинга лишь немного превышает качество логистической регрессии, при значительно более высокой сложности модели.  \n",
    "Можно предпложить что модель относит к токсичным комментарии, содержащий нецензурную, грубую и т.д. лексику. Проверим, какие признаки являются наиболее значимыми для лучшей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = model_lr_uni.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова характеризующие токсичность комментария: \n",
      "\n",
      "['scum' 'retarded' 'homosexual' 'sick' 'kill' 'nazi' 'fat' 'fuckin' 'hate'\n",
      " 'ignorant' 'wtf' 'pussy' 'piss' 'retard' 'fool' 'fucker' 'pathetic'\n",
      " 'racist' 'fag' 'cock' 'sex' 'dumbass' 'dumb' 'you' 'fucked' 'die' 'loser'\n",
      " 'shut' 'jerk' 'damn' 'gay' 'penis' 'nigger' 'bastard' 'moron' 'hell'\n",
      " 'faggot' 'cunt' 'crap' 'bullshit' 'dick' 'asshole' 'bitch' 'suck' 'as'\n",
      " 'stupid' 'idiot' 'shit' 'fucking' 'fuck']\n",
      "\n",
      " Слова характеризующие \"антитоксичность\" комментария: \n",
      "\n",
      "['thank' 'thanks' 'talk' 'please' 'if' 'best' 'utc' 'welcome' 'for'\n",
      " 'redirect' 'help' 'appreciate' 'section' 'cheer' 'consensus' 'may'\n",
      " 'article' 'see' 'could' 'point' 'continue' 'issue' 'agree' 'support'\n",
      " 'request' 'interested' 'under' 'version' 'there' 'from' 'tag' 'at'\n",
      " 'reference' 'sure' 'in' 'but' 'provide' 'list' 'need' 'ask' 'apologize'\n",
      " 'number' 'dispute' 'source' 'case' 'wp' 'review' 'didn' 'involved'\n",
      " 'started']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer_uni.vocabulary_\n",
    "vocab = pd.DataFrame({'name':vocab.keys()}, index=vocab.values()\n",
    "                    ).sort_index()\n",
    "vocab['coeff']=coeffs\n",
    "print('Слова характеризующие токсичность комментария:', '\\n')\n",
    "print(vocab.sort_values(by='coeff').tail(50)['name'].values)\n",
    "\n",
    "print('\\n', 'Слова характеризующие \"антитоксичность\" комментария:', '\\n')\n",
    "print(vocab.sort_values(by='coeff').head(50)['name'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это действительно так. Отсюда сразу следует уязвимость построенных моделей: добавление позитивных слов может скрыть от модели явно негативный комментарий, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фраза: thank you stupid jerk please welcome in this section for help and interested reference \n",
      "\n",
      "Предсказание логистической регрессии: 0\n",
      "Предсказание градиентного бустинга: 0\n"
     ]
    }
   ],
   "source": [
    "test_string = ['thank you stupid jerk please welcome in this section for help and interested reference']\n",
    "test_string_vec = vectorizer_uni.transform(test_string)\n",
    "print('Фраза:', test_string[0], '\\n')\n",
    "print(\"Предсказание логистической регрессии:\", model_lr_uni.predict(test_string_vec)[0])\n",
    "print(\"Предсказание градиентного бустинга:\", model_cat.predict(test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели были обмануты, сократим количество позитивных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фраза: thank you stupid jerk please welcome in this section for help and reference \n",
      "\n",
      "Предсказание логистической регрессии: 0\n",
      "Предсказание градиентного бустинга: 1\n",
      "\n",
      "Фраза: thank you stupid jerk please welcome in this section for help \n",
      "\n",
      "Предсказание логистической регрессии: 1\n",
      "Предсказание градиентного бустинга: 1\n"
     ]
    }
   ],
   "source": [
    "test_string = ['thank you stupid jerk please welcome in this section for help and reference']\n",
    "test_string_vec = vectorizer_uni.transform(test_string)\n",
    "print('Фраза:', test_string[0], '\\n')\n",
    "print(\"Предсказание логистической регрессии:\", model_lr_uni.predict(test_string_vec)[0])\n",
    "print(\"Предсказание градиентного бустинга:\", model_cat.predict(test_string))\n",
    "\n",
    "test_string = ['thank you stupid jerk please welcome in this section for help']\n",
    "test_string_vec = vectorizer_uni.transform(test_string)\n",
    "\n",
    "print('\\nФраза:', test_string[0], '\\n')\n",
    "print(\"Предсказание логистической регрессии:\", model_lr_uni.predict(test_string_vec)[0])\n",
    "print(\"Предсказание градиентного бустинга:\", model_cat.predict(test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев логистическая регрессия и градиентный бустинг работают одинаково (одинаково хорошо и одинаково плохо).  \n",
    "Немного исправить ситуацию можно обучая модели на n-граммах большего чем 1 порядка, ограничив при этом словарь только самыми значимыми позитивными и негативными словами. Выделим 500 слов с наибольшим абсолютным значением коэффициента в линейной модели и заново векторизуем тексты, используя только эти слова в словаре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['acoeff'] = vocab.coeff.abs()\n",
    "top_words_500 = vocab.sort_values(by='acoeff').tail(500)['name'].values\n",
    "\n",
    "vectorizer_top = TfidfVectorizer(ngram_range=(1, 2), vocabulary=top_words_500)\n",
    "\n",
    "comments_top_words = []\n",
    "vectorizer_top.fit(train.text)\n",
    "for part in [train, val, test]:\n",
    "    comments_top_words.append(vectorizer_top.transform(part.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново обучим модель логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_top = LogisticRegression(random_state=123)\n",
    "model_lr_top.fit(comments_top_words[0], train.toxic)\n",
    "f1_score(val.toxic, model_lr_top.predict(comments_top_words[1])).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение F1-метрики: 0.780 при пороге 0.347\n"
     ]
    }
   ],
   "source": [
    "best_thres_lr_top = thresh_opti(model_lr_top, val.toxic, comments_top_words[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось дополнительно улучшить целевую метрику. Требуемый порог целевой метрики удалось преодолеть используя только 500 слов, однако улучшить ситуацию с ложно-отрицательными предсказаниями это не помогает.  Проверим итоговую модель на отложенной тестовой выборке:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test.toxic, \n",
    "         model_lr_top.predict_proba(comments_top_words[2])[:, 1] > best_thres_lr_top).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F1-метрики на тестовой выборке превосходит 0.75, таким образом, выбранная модель удовлетворяет предъявленным к ней требованиям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Требуемый порог F1-метрики может быть достигнут при использовании модели логистической регрессии и tf-idf векторизации текста комментариев.\n",
    "2. Использование градиентного бустинга слабо улучшает целевую метрику при использовании tf-idf векторизации.\n",
    "3. Повысить точность предсказаний и ускорить обучение и работу моделей можно ограничив словарь только обсценной, грубой и т.д. лексикой.\n",
    "4. Общей проблемой исследованных моделей при tf-idf векторизации текста является легкость получения ложноотрицательных предсказаний. Добавление \"позитивных\", в том числе бесмысленных, слов маскирует явно токсичные комментарии.\n",
    "5. При необходимости повысить качество моделей можно путем улучшения векторизации - качественный отбор словаря, учет контекста, создание представлений с помощью нейросетей (BERT и т.д.)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 772,
    "start_time": "2022-08-28T10:37:41.018Z"
   },
   {
    "duration": 71,
    "start_time": "2022-08-28T10:37:49.494Z"
   },
   {
    "duration": 40,
    "start_time": "2022-08-28T10:38:14.021Z"
   },
   {
    "duration": 46,
    "start_time": "2022-08-28T10:38:27.253Z"
   },
   {
    "duration": 2191,
    "start_time": "2022-08-28T10:38:31.443Z"
   },
   {
    "duration": 1784,
    "start_time": "2022-08-28T10:38:43.078Z"
   },
   {
    "duration": 2180,
    "start_time": "2022-08-28T10:38:50.023Z"
   },
   {
    "duration": 780,
    "start_time": "2022-08-28T10:38:58.021Z"
   },
   {
    "duration": 31,
    "start_time": "2022-08-28T10:41:23.258Z"
   },
   {
    "duration": 207,
    "start_time": "2022-08-28T10:41:31.385Z"
   },
   {
    "duration": 190,
    "start_time": "2022-08-28T10:41:36.851Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T10:42:52.646Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-28T10:43:44.957Z"
   },
   {
    "duration": 27,
    "start_time": "2022-08-28T10:43:52.096Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-28T10:44:00.763Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-28T10:44:11.921Z"
   },
   {
    "duration": 60,
    "start_time": "2022-08-28T10:44:50.369Z"
   },
   {
    "duration": 202,
    "start_time": "2022-08-28T10:45:08.498Z"
   },
   {
    "duration": 219,
    "start_time": "2022-08-28T10:45:24.641Z"
   },
   {
    "duration": 207,
    "start_time": "2022-08-28T10:45:35.521Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T10:46:32.325Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T10:46:39.487Z"
   },
   {
    "duration": 407,
    "start_time": "2022-08-28T10:46:44.882Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T10:47:36.256Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T10:48:13.087Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T10:48:15.863Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T10:48:24.029Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T10:48:33.680Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T10:48:56.760Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-28T10:49:12.501Z"
   },
   {
    "duration": 157,
    "start_time": "2022-08-28T10:49:35.057Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T10:50:09.320Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T10:50:18.125Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T10:50:46.698Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T10:51:20.025Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T10:51:38.745Z"
   },
   {
    "duration": 6466,
    "start_time": "2022-08-28T10:51:51.443Z"
   },
   {
    "duration": 893,
    "start_time": "2022-08-28T10:52:00.700Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T10:52:39.200Z"
   },
   {
    "duration": 106,
    "start_time": "2022-08-28T10:52:50.893Z"
   },
   {
    "duration": 1611,
    "start_time": "2022-08-28T10:53:16.621Z"
   },
   {
    "duration": 1695,
    "start_time": "2022-08-28T10:53:38.723Z"
   },
   {
    "duration": 1617,
    "start_time": "2022-08-28T10:53:49.084Z"
   },
   {
    "duration": 6454,
    "start_time": "2022-08-28T10:54:19.542Z"
   },
   {
    "duration": 6468,
    "start_time": "2022-08-28T10:54:51.615Z"
   },
   {
    "duration": 6266,
    "start_time": "2022-08-28T10:55:30.985Z"
   },
   {
    "duration": 205,
    "start_time": "2022-08-28T10:57:09.076Z"
   },
   {
    "duration": 3427,
    "start_time": "2022-08-28T10:57:23.970Z"
   },
   {
    "duration": 3504,
    "start_time": "2022-08-28T10:57:44.826Z"
   },
   {
    "duration": 3484,
    "start_time": "2022-08-28T10:58:08.478Z"
   },
   {
    "duration": 3407,
    "start_time": "2022-08-28T10:58:21.018Z"
   },
   {
    "duration": 3598,
    "start_time": "2022-08-28T10:58:31.457Z"
   },
   {
    "duration": 3460,
    "start_time": "2022-08-28T10:58:52.295Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:00:07.691Z"
   },
   {
    "duration": 55,
    "start_time": "2022-08-28T11:00:12.400Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:00:16.544Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:00:18.276Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:00:26.328Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:00:29.318Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:01:05.464Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:01:10.679Z"
   },
   {
    "duration": 3355,
    "start_time": "2022-08-28T11:01:59.967Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:02:16.859Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:16:31.099Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:16:55.641Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:16:59.732Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:17:15.524Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:17:27.845Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:17:31.397Z"
   },
   {
    "duration": 3434,
    "start_time": "2022-08-28T11:18:59.871Z"
   },
   {
    "duration": 3406,
    "start_time": "2022-08-28T11:21:14.791Z"
   },
   {
    "duration": 3473,
    "start_time": "2022-08-28T11:21:32.041Z"
   },
   {
    "duration": 3391,
    "start_time": "2022-08-28T11:21:43.726Z"
   },
   {
    "duration": 3582,
    "start_time": "2022-08-28T11:21:53.230Z"
   },
   {
    "duration": 4374,
    "start_time": "2022-08-28T11:27:12.230Z"
   },
   {
    "duration": 3976,
    "start_time": "2022-08-28T11:27:18.274Z"
   },
   {
    "duration": 818,
    "start_time": "2022-08-28T11:38:30.750Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:41:29.033Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T11:42:11.000Z"
   },
   {
    "duration": 873,
    "start_time": "2022-08-28T11:42:31.662Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:42:41.645Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-28T11:42:51.590Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-28T11:43:28.097Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-28T11:43:39.198Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:44:12.138Z"
   },
   {
    "duration": 1230,
    "start_time": "2022-08-28T11:44:19.258Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T11:44:34.187Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:44:40.830Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:45:09.485Z"
   },
   {
    "duration": 2305,
    "start_time": "2022-08-28T11:45:51.484Z"
   },
   {
    "duration": 699,
    "start_time": "2022-08-28T11:46:52.644Z"
   },
   {
    "duration": 2537,
    "start_time": "2022-08-28T11:47:03.338Z"
   },
   {
    "duration": 2470,
    "start_time": "2022-08-28T11:47:23.264Z"
   },
   {
    "duration": 2586,
    "start_time": "2022-08-28T11:47:42.380Z"
   },
   {
    "duration": 4421,
    "start_time": "2022-08-28T11:47:54.368Z"
   },
   {
    "duration": 714,
    "start_time": "2022-08-28T11:48:03.363Z"
   },
   {
    "duration": 3399,
    "start_time": "2022-08-28T11:48:07.681Z"
   },
   {
    "duration": 3455,
    "start_time": "2022-08-28T11:48:22.433Z"
   },
   {
    "duration": 3716,
    "start_time": "2022-08-28T11:48:33.863Z"
   },
   {
    "duration": 4853,
    "start_time": "2022-08-28T11:50:06.584Z"
   },
   {
    "duration": 763,
    "start_time": "2022-08-28T11:50:35.457Z"
   },
   {
    "duration": 5537,
    "start_time": "2022-08-28T11:50:43.379Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T11:50:58.655Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:51:00.036Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:51:15.851Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T11:51:36.865Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:51:43.600Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:51:48.206Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:51:50.914Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-28T11:52:24.101Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:52:26.975Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T11:52:28.901Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T11:52:59.444Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T11:53:02.231Z"
   },
   {
    "duration": 28931,
    "start_time": "2022-08-28T11:53:52.934Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T12:33:21.073Z"
   },
   {
    "duration": 7377,
    "start_time": "2022-08-28T12:34:52.550Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-28T12:37:57.527Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-28T12:38:06.733Z"
   },
   {
    "duration": 24,
    "start_time": "2022-08-28T12:38:12.693Z"
   },
   {
    "duration": 7265,
    "start_time": "2022-08-28T12:38:14.652Z"
   },
   {
    "duration": 56924,
    "start_time": "2022-08-28T12:38:27.516Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-28T12:39:36.919Z"
   },
   {
    "duration": 6873,
    "start_time": "2022-08-28T12:39:43.941Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T12:39:52.314Z"
   },
   {
    "duration": 147061,
    "start_time": "2022-08-28T12:39:54.862Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T12:43:34.170Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T12:43:49.433Z"
   },
   {
    "duration": 198,
    "start_time": "2022-08-28T12:44:02.422Z"
   },
   {
    "duration": 47727,
    "start_time": "2022-08-28T12:44:10.018Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T12:45:19.723Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T12:46:15.286Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-28T12:46:17.158Z"
   },
   {
    "duration": 55344,
    "start_time": "2022-08-28T12:46:21.215Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-28T12:47:33.766Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T12:47:35.616Z"
   },
   {
    "duration": 56031,
    "start_time": "2022-08-28T12:47:59.923Z"
   },
   {
    "duration": 55603,
    "start_time": "2022-08-28T12:49:07.443Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T12:51:45.028Z"
   },
   {
    "duration": 516,
    "start_time": "2022-08-28T12:52:36.277Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-28T12:53:10.680Z"
   },
   {
    "duration": 147807,
    "start_time": "2022-08-28T12:53:15.247Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-28T12:55:43.056Z"
   },
   {
    "duration": 563,
    "start_time": "2022-08-28T12:55:43.086Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-28T12:56:02.128Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-28T12:56:15.431Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-28T12:56:17.840Z"
   },
   {
    "duration": 479,
    "start_time": "2022-08-28T12:56:39.266Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-28T12:56:44.126Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T12:56:52.944Z"
   },
   {
    "duration": 190,
    "start_time": "2022-08-28T12:57:04.979Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T12:58:25.551Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T12:58:25.552Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T12:58:33.346Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-28T12:58:39.052Z"
   },
   {
    "duration": 215,
    "start_time": "2022-08-28T12:58:50.166Z"
   },
   {
    "duration": 95602,
    "start_time": "2022-08-28T12:58:52.849Z"
   },
   {
    "duration": 315,
    "start_time": "2022-08-28T13:02:11.929Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T13:02:33.057Z"
   },
   {
    "duration": 213,
    "start_time": "2022-08-28T13:02:59.178Z"
   },
   {
    "duration": 6581,
    "start_time": "2022-08-28T13:03:30.034Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-28T13:03:40.347Z"
   },
   {
    "duration": 6776,
    "start_time": "2022-08-28T13:03:43.342Z"
   },
   {
    "duration": 76,
    "start_time": "2022-08-28T13:04:37.394Z"
   },
   {
    "duration": 1030,
    "start_time": "2022-08-28T13:04:41.796Z"
   },
   {
    "duration": 7160,
    "start_time": "2022-08-28T13:04:55.189Z"
   },
   {
    "duration": 85,
    "start_time": "2022-08-28T13:05:03.584Z"
   },
   {
    "duration": 22145,
    "start_time": "2022-08-28T13:05:06.326Z"
   },
   {
    "duration": 6713,
    "start_time": "2022-08-28T13:05:38.425Z"
   },
   {
    "duration": 89,
    "start_time": "2022-08-28T13:05:48.536Z"
   },
   {
    "duration": 18210,
    "start_time": "2022-08-28T13:05:50.671Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-28T13:06:59.876Z"
   },
   {
    "duration": 7370,
    "start_time": "2022-08-28T13:07:06.092Z"
   },
   {
    "duration": 154,
    "start_time": "2022-08-28T13:07:22.560Z"
   },
   {
    "duration": 40585,
    "start_time": "2022-08-28T13:07:24.880Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T13:08:28.296Z"
   },
   {
    "duration": 6838,
    "start_time": "2022-08-28T13:08:30.548Z"
   },
   {
    "duration": 35156,
    "start_time": "2022-08-28T13:08:40.376Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-28T13:09:26.655Z"
   },
   {
    "duration": 6806,
    "start_time": "2022-08-28T13:09:28.726Z"
   },
   {
    "duration": 32225,
    "start_time": "2022-08-28T13:09:39.625Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-28T13:10:24.055Z"
   },
   {
    "duration": 6613,
    "start_time": "2022-08-28T13:10:26.328Z"
   },
   {
    "duration": 31645,
    "start_time": "2022-08-28T13:10:34.225Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-28T13:11:13.975Z"
   },
   {
    "duration": 18870,
    "start_time": "2022-08-28T13:11:16.147Z"
   },
   {
    "duration": 61762,
    "start_time": "2022-08-28T13:11:38.429Z"
   },
   {
    "duration": 61087,
    "start_time": "2022-08-28T13:13:34.823Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-28T13:14:35.912Z"
   },
   {
    "duration": 445685,
    "start_time": "2022-08-28T13:15:35.576Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T13:23:01.263Z"
   },
   {
    "duration": 27,
    "start_time": "2022-08-28T13:25:16.749Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T13:27:26.468Z"
   },
   {
    "duration": 794,
    "start_time": "2022-08-28T13:27:26.473Z"
   },
   {
    "duration": 243,
    "start_time": "2022-08-28T13:27:27.269Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T13:27:27.515Z"
   },
   {
    "duration": 1360,
    "start_time": "2022-08-28T13:27:36.879Z"
   },
   {
    "duration": 909,
    "start_time": "2022-08-28T13:27:38.241Z"
   },
   {
    "duration": 252,
    "start_time": "2022-08-28T13:27:39.151Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T13:27:39.406Z"
   },
   {
    "duration": 3378,
    "start_time": "2022-08-28T13:27:39.412Z"
   },
   {
    "duration": 5634,
    "start_time": "2022-08-28T13:27:42.792Z"
   },
   {
    "duration": 31231,
    "start_time": "2022-08-28T13:27:48.428Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-28T13:28:19.661Z"
   },
   {
    "duration": 124,
    "start_time": "2022-08-28T13:28:19.686Z"
   },
   {
    "duration": 20533,
    "start_time": "2022-08-28T13:28:22.181Z"
   },
   {
    "duration": 22842,
    "start_time": "2022-08-28T13:31:17.069Z"
   },
   {
    "duration": 33103,
    "start_time": "2022-08-28T13:35:32.543Z"
   },
   {
    "duration": 32805,
    "start_time": "2022-08-28T13:36:45.834Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T13:40:23.312Z"
   },
   {
    "duration": 815,
    "start_time": "2022-08-28T13:40:48.751Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T13:40:59.902Z"
   },
   {
    "duration": 782,
    "start_time": "2022-08-28T13:41:01.630Z"
   },
   {
    "duration": 735,
    "start_time": "2022-08-28T13:41:24.970Z"
   },
   {
    "duration": 77419,
    "start_time": "2022-08-28T15:13:38.632Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-28T15:15:58.825Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-28T15:16:13.900Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-28T15:16:27.210Z"
   },
   {
    "duration": 80883,
    "start_time": "2022-08-28T15:16:51.669Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T15:18:12.554Z"
   },
   {
    "duration": 1170,
    "start_time": "2022-08-28T15:18:23.653Z"
   },
   {
    "duration": 73991,
    "start_time": "2022-08-28T15:18:37.056Z"
   },
   {
    "duration": 1204,
    "start_time": "2022-08-28T15:19:51.050Z"
   },
   {
    "duration": 50,
    "start_time": "2022-08-28T15:20:46.344Z"
   },
   {
    "duration": 1137,
    "start_time": "2022-08-28T15:20:56.411Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T15:21:35.670Z"
   },
   {
    "duration": 120000,
    "start_time": "2022-08-28T15:22:09.033Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T15:26:20.246Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T15:26:20.247Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T15:26:23.504Z"
   },
   {
    "duration": 290054,
    "start_time": "2022-08-28T15:26:25.348Z"
   },
   {
    "duration": 54,
    "start_time": "2022-08-28T15:32:03.438Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:32:06.516Z"
   },
   {
    "duration": 160716,
    "start_time": "2022-08-28T15:32:08.395Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-28T15:35:26.297Z"
   },
   {
    "duration": 44042,
    "start_time": "2022-08-28T15:37:23.906Z"
   },
   {
    "duration": 20714,
    "start_time": "2022-08-28T15:38:18.165Z"
   },
   {
    "duration": 23585,
    "start_time": "2022-08-28T15:38:38.882Z"
   },
   {
    "duration": 35270,
    "start_time": "2022-08-28T15:39:02.469Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:39:37.742Z"
   },
   {
    "duration": 729,
    "start_time": "2022-08-28T15:39:37.747Z"
   },
   {
    "duration": 59673,
    "start_time": "2022-08-28T15:39:38.478Z"
   },
   {
    "duration": 1155,
    "start_time": "2022-08-28T15:40:38.153Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:40:39.309Z"
   },
   {
    "duration": 36423,
    "start_time": "2022-08-28T15:40:39.314Z"
   },
   {
    "duration": 20423,
    "start_time": "2022-08-28T15:41:28.687Z"
   },
   {
    "duration": 22548,
    "start_time": "2022-08-28T15:41:49.112Z"
   },
   {
    "duration": 36394,
    "start_time": "2022-08-28T15:42:11.661Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T15:42:48.057Z"
   },
   {
    "duration": 764,
    "start_time": "2022-08-28T15:42:48.063Z"
   },
   {
    "duration": 51330,
    "start_time": "2022-08-28T15:42:48.829Z"
   },
   {
    "duration": 1016,
    "start_time": "2022-08-28T15:43:40.161Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:43:41.178Z"
   },
   {
    "duration": 1580,
    "start_time": "2022-08-28T15:45:39.759Z"
   },
   {
    "duration": 884,
    "start_time": "2022-08-28T15:45:41.341Z"
   },
   {
    "duration": 256,
    "start_time": "2022-08-28T15:45:42.227Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T15:45:42.486Z"
   },
   {
    "duration": 3506,
    "start_time": "2022-08-28T15:45:42.492Z"
   },
   {
    "duration": 5444,
    "start_time": "2022-08-28T15:45:46.000Z"
   },
   {
    "duration": 31249,
    "start_time": "2022-08-28T15:45:51.446Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-28T15:46:22.697Z"
   },
   {
    "duration": 19872,
    "start_time": "2022-08-28T15:46:22.722Z"
   },
   {
    "duration": 22397,
    "start_time": "2022-08-28T15:46:42.596Z"
   },
   {
    "duration": 30445,
    "start_time": "2022-08-28T15:47:04.994Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T15:47:35.441Z"
   },
   {
    "duration": 755,
    "start_time": "2022-08-28T15:47:35.446Z"
   },
   {
    "duration": 49239,
    "start_time": "2022-08-28T15:47:36.203Z"
   },
   {
    "duration": 945,
    "start_time": "2022-08-28T15:48:25.444Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:48:26.391Z"
   },
   {
    "duration": 212599,
    "start_time": "2022-08-28T15:48:26.396Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T15:51:58.997Z"
   },
   {
    "duration": 1070,
    "start_time": "2022-08-28T15:52:16.346Z"
   },
   {
    "duration": 1057,
    "start_time": "2022-08-28T15:52:23.350Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:52:35.922Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-08-28T15:52:37.105Z"
   },
   {
    "duration": 1041,
    "start_time": "2022-08-28T15:53:03.043Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T15:53:18.740Z"
   },
   {
    "duration": 3795193,
    "start_time": "2022-08-28T15:53:20.524Z"
   },
   {
    "duration": 283,
    "start_time": "2022-08-28T17:15:59.765Z"
   },
   {
    "duration": 14179,
    "start_time": "2022-08-28T17:16:42.659Z"
   },
   {
    "duration": 31,
    "start_time": "2022-08-28T17:18:51.831Z"
   },
   {
    "duration": 13853,
    "start_time": "2022-08-28T17:18:54.729Z"
   },
   {
    "duration": 21513,
    "start_time": "2022-08-28T17:19:09.088Z"
   },
   {
    "duration": 14243,
    "start_time": "2022-08-28T17:19:30.603Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T17:19:47.853Z"
   },
   {
    "duration": 1285,
    "start_time": "2022-08-28T17:19:56.796Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-28T17:20:07.721Z"
   },
   {
    "duration": 18617,
    "start_time": "2022-08-28T17:20:10.068Z"
   },
   {
    "duration": 21628,
    "start_time": "2022-08-28T17:20:28.686Z"
   },
   {
    "duration": 37834,
    "start_time": "2022-08-28T17:20:50.316Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T17:21:28.152Z"
   },
   {
    "duration": 873,
    "start_time": "2022-08-28T17:21:28.158Z"
   },
   {
    "duration": 38310,
    "start_time": "2022-08-28T17:21:29.033Z"
   },
   {
    "duration": 1110,
    "start_time": "2022-08-28T17:22:07.345Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-28T17:22:08.457Z"
   },
   {
    "duration": 165740,
    "start_time": "2022-08-28T17:22:08.470Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:24:54.212Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:24:54.213Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:24:54.214Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:24:54.216Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:24:54.216Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T17:24:57.876Z"
   },
   {
    "duration": 296637,
    "start_time": "2022-08-28T17:24:59.425Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:29:56.064Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:29:56.066Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:29:56.067Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:29:56.069Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T17:29:56.071Z"
   },
   {
    "duration": 1587,
    "start_time": "2022-08-28T17:30:04.135Z"
   },
   {
    "duration": 924,
    "start_time": "2022-08-28T17:30:05.724Z"
   },
   {
    "duration": 267,
    "start_time": "2022-08-28T17:30:06.649Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-28T17:30:06.917Z"
   },
   {
    "duration": 3614,
    "start_time": "2022-08-28T17:30:06.923Z"
   },
   {
    "duration": 5370,
    "start_time": "2022-08-28T17:30:10.539Z"
   },
   {
    "duration": 31141,
    "start_time": "2022-08-28T17:30:15.911Z"
   },
   {
    "duration": 24,
    "start_time": "2022-08-28T17:30:47.054Z"
   },
   {
    "duration": 19443,
    "start_time": "2022-08-28T17:30:47.080Z"
   },
   {
    "duration": 21718,
    "start_time": "2022-08-28T17:31:06.525Z"
   },
   {
    "duration": 35302,
    "start_time": "2022-08-28T17:31:28.245Z"
   },
   {
    "duration": 90,
    "start_time": "2022-08-28T17:32:03.549Z"
   },
   {
    "duration": 841,
    "start_time": "2022-08-28T17:32:03.641Z"
   },
   {
    "duration": 38160,
    "start_time": "2022-08-28T17:32:04.484Z"
   },
   {
    "duration": 1159,
    "start_time": "2022-08-28T17:32:42.647Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T17:32:43.807Z"
   },
   {
    "duration": 2110377,
    "start_time": "2022-08-28T17:32:43.813Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:07:54.191Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:07:54.193Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:07:54.194Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:07:54.195Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:07:54.196Z"
   },
   {
    "duration": 1597,
    "start_time": "2022-08-28T18:08:34.529Z"
   },
   {
    "duration": 883,
    "start_time": "2022-08-28T18:08:36.128Z"
   },
   {
    "duration": 260,
    "start_time": "2022-08-28T18:08:37.013Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T18:08:37.275Z"
   },
   {
    "duration": 3527,
    "start_time": "2022-08-28T18:08:37.281Z"
   },
   {
    "duration": 5466,
    "start_time": "2022-08-28T18:08:40.809Z"
   },
   {
    "duration": 32271,
    "start_time": "2022-08-28T18:08:46.277Z"
   },
   {
    "duration": 35,
    "start_time": "2022-08-28T18:09:18.550Z"
   },
   {
    "duration": 20091,
    "start_time": "2022-08-28T18:09:18.587Z"
   },
   {
    "duration": 23117,
    "start_time": "2022-08-28T18:09:38.681Z"
   },
   {
    "duration": 39062,
    "start_time": "2022-08-28T18:10:01.800Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-28T18:10:40.939Z"
   },
   {
    "duration": 854,
    "start_time": "2022-08-28T18:10:40.949Z"
   },
   {
    "duration": 38444,
    "start_time": "2022-08-28T18:10:41.805Z"
   },
   {
    "duration": 1153,
    "start_time": "2022-08-28T18:11:20.251Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T18:11:21.406Z"
   },
   {
    "duration": 1324788,
    "start_time": "2022-08-28T18:11:21.410Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:33:26.200Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:33:26.201Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:33:26.202Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:33:26.203Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:33:26.204Z"
   },
   {
    "duration": 1858,
    "start_time": "2022-08-28T18:33:55.181Z"
   },
   {
    "duration": 34692,
    "start_time": "2022-08-28T18:35:02.566Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T18:35:37.260Z"
   },
   {
    "duration": 33657,
    "start_time": "2022-08-28T18:36:36.989Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T18:37:16.635Z"
   },
   {
    "duration": 31044,
    "start_time": "2022-08-28T18:37:18.732Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:37:49.777Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-28T18:37:52.229Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:39:51.044Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-28T18:39:51.045Z"
   },
   {
    "duration": 40039,
    "start_time": "2022-08-28T18:39:57.253Z"
   },
   {
    "duration": 2915,
    "start_time": "2022-08-28T18:40:57.108Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-28T18:41:41.684Z"
   },
   {
    "duration": 179790,
    "start_time": "2022-08-28T18:42:49.484Z"
   },
   {
    "duration": 20124,
    "start_time": "2022-08-28T18:45:56.098Z"
   },
   {
    "duration": 9121,
    "start_time": "2022-08-28T18:47:29.294Z"
   },
   {
    "duration": 53,
    "start_time": "2022-08-28T18:48:33.770Z"
   },
   {
    "duration": 43,
    "start_time": "2022-08-28T18:48:41.781Z"
   },
   {
    "duration": 13318,
    "start_time": "2022-08-28T18:48:47.258Z"
   },
   {
    "duration": 21446,
    "start_time": "2022-08-28T18:51:34.900Z"
   },
   {
    "duration": 23884,
    "start_time": "2022-08-28T18:52:14.956Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-28T18:52:51.730Z"
   },
   {
    "duration": 389,
    "start_time": "2022-08-28T18:52:55.800Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-28T18:54:07.630Z"
   },
   {
    "duration": 36782,
    "start_time": "2022-08-28T18:54:22.267Z"
   },
   {
    "duration": 498,
    "start_time": "2022-08-28T18:56:28.637Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-28T18:59:12.606Z"
   },
   {
    "duration": 17018,
    "start_time": "2022-08-28T18:59:33.044Z"
   },
   {
    "duration": 169,
    "start_time": "2022-08-28T19:01:06.146Z"
   },
   {
    "duration": 310339,
    "start_time": "2022-08-28T19:01:13.741Z"
   },
   {
    "duration": 4575,
    "start_time": "2022-08-28T19:06:31.706Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T19:06:58.615Z"
   },
   {
    "duration": 704440,
    "start_time": "2022-08-28T19:07:00.859Z"
   },
   {
    "duration": 13141,
    "start_time": "2022-08-28T19:18:45.301Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-28T19:23:24.629Z"
   },
   {
    "duration": 1682,
    "start_time": "2022-08-29T09:49:48.744Z"
   },
   {
    "duration": 2350,
    "start_time": "2022-08-29T09:49:51.724Z"
   },
   {
    "duration": 238,
    "start_time": "2022-08-29T09:49:54.730Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T09:49:57.445Z"
   },
   {
    "duration": 3771,
    "start_time": "2022-08-29T09:50:00.974Z"
   },
   {
    "duration": 5392,
    "start_time": "2022-08-29T09:50:15.305Z"
   },
   {
    "duration": 30508,
    "start_time": "2022-08-29T09:50:20.698Z"
   },
   {
    "duration": 34,
    "start_time": "2022-08-29T09:51:54.596Z"
   },
   {
    "duration": 12305,
    "start_time": "2022-08-29T09:52:52.324Z"
   },
   {
    "duration": 20609,
    "start_time": "2022-08-29T09:53:04.631Z"
   },
   {
    "duration": 20541,
    "start_time": "2022-08-29T09:54:05.501Z"
   },
   {
    "duration": 12305,
    "start_time": "2022-08-29T09:54:36.692Z"
   },
   {
    "duration": 20745,
    "start_time": "2022-08-29T09:54:49.000Z"
   },
   {
    "duration": 26596,
    "start_time": "2022-08-29T09:55:09.747Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T09:55:36.344Z"
   },
   {
    "duration": 359,
    "start_time": "2022-08-29T09:55:36.350Z"
   },
   {
    "duration": 32639,
    "start_time": "2022-08-29T09:55:36.710Z"
   },
   {
    "duration": 467,
    "start_time": "2022-08-29T09:56:09.439Z"
   },
   {
    "duration": 12669,
    "start_time": "2022-08-29T09:57:58.047Z"
   },
   {
    "duration": 21444,
    "start_time": "2022-08-29T09:58:10.718Z"
   },
   {
    "duration": 26088,
    "start_time": "2022-08-29T09:58:32.163Z"
   },
   {
    "duration": 87,
    "start_time": "2022-08-29T09:58:58.254Z"
   },
   {
    "duration": 385,
    "start_time": "2022-08-29T09:58:58.343Z"
   },
   {
    "duration": 12278,
    "start_time": "2022-08-29T09:59:13.840Z"
   },
   {
    "duration": 19275,
    "start_time": "2022-08-29T09:59:31.218Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T09:59:50.495Z"
   },
   {
    "duration": 1221,
    "start_time": "2022-08-29T10:00:02.391Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:00:05.822Z"
   },
   {
    "duration": 370,
    "start_time": "2022-08-29T10:00:09.038Z"
   },
   {
    "duration": 12459,
    "start_time": "2022-08-29T10:00:21.571Z"
   },
   {
    "duration": 20057,
    "start_time": "2022-08-29T10:00:34.032Z"
   },
   {
    "duration": 1234,
    "start_time": "2022-08-29T10:00:54.091Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T10:00:55.327Z"
   },
   {
    "duration": 353,
    "start_time": "2022-08-29T10:01:11.285Z"
   },
   {
    "duration": 70,
    "start_time": "2022-08-29T10:01:16.806Z"
   },
   {
    "duration": 355010,
    "start_time": "2022-08-29T10:01:24.165Z"
   },
   {
    "duration": 28833,
    "start_time": "2022-08-29T10:07:20.866Z"
   },
   {
    "duration": 1473,
    "start_time": "2022-08-29T10:10:19.757Z"
   },
   {
    "duration": 895,
    "start_time": "2022-08-29T10:10:21.232Z"
   },
   {
    "duration": 257,
    "start_time": "2022-08-29T10:10:22.129Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T10:10:22.389Z"
   },
   {
    "duration": 3540,
    "start_time": "2022-08-29T10:10:22.395Z"
   },
   {
    "duration": 5449,
    "start_time": "2022-08-29T10:10:25.938Z"
   },
   {
    "duration": 31758,
    "start_time": "2022-08-29T10:10:31.388Z"
   },
   {
    "duration": 58,
    "start_time": "2022-08-29T10:11:03.148Z"
   },
   {
    "duration": 12728,
    "start_time": "2022-08-29T10:11:03.208Z"
   },
   {
    "duration": 20278,
    "start_time": "2022-08-29T10:11:15.940Z"
   },
   {
    "duration": 1363,
    "start_time": "2022-08-29T10:11:36.220Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:11:37.584Z"
   },
   {
    "duration": 394,
    "start_time": "2022-08-29T10:11:37.590Z"
   },
   {
    "duration": 33853,
    "start_time": "2022-08-29T10:11:37.986Z"
   },
   {
    "duration": 412,
    "start_time": "2022-08-29T10:12:11.841Z"
   },
   {
    "duration": 39133,
    "start_time": "2022-08-29T10:12:12.255Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:12:51.390Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:12:51.392Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:12:51.393Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:12:51.395Z"
   },
   {
    "duration": 1526,
    "start_time": "2022-08-29T10:13:06.130Z"
   },
   {
    "duration": 881,
    "start_time": "2022-08-29T10:13:07.658Z"
   },
   {
    "duration": 259,
    "start_time": "2022-08-29T10:13:08.541Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:13:08.802Z"
   },
   {
    "duration": 3522,
    "start_time": "2022-08-29T10:13:08.808Z"
   },
   {
    "duration": 5393,
    "start_time": "2022-08-29T10:13:12.332Z"
   },
   {
    "duration": 30757,
    "start_time": "2022-08-29T10:13:17.727Z"
   },
   {
    "duration": 32,
    "start_time": "2022-08-29T10:13:48.486Z"
   },
   {
    "duration": 12648,
    "start_time": "2022-08-29T10:13:48.520Z"
   },
   {
    "duration": 19829,
    "start_time": "2022-08-29T10:14:01.171Z"
   },
   {
    "duration": 1405,
    "start_time": "2022-08-29T10:14:21.001Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:14:22.407Z"
   },
   {
    "duration": 377,
    "start_time": "2022-08-29T10:14:22.412Z"
   },
   {
    "duration": 28356,
    "start_time": "2022-08-29T10:14:22.791Z"
   },
   {
    "duration": 494,
    "start_time": "2022-08-29T10:14:51.148Z"
   },
   {
    "duration": 12407,
    "start_time": "2022-08-29T10:14:51.644Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:15:04.053Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:15:04.055Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:15:04.056Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:15:04.058Z"
   },
   {
    "duration": 1496,
    "start_time": "2022-08-29T10:16:00.651Z"
   },
   {
    "duration": 885,
    "start_time": "2022-08-29T10:16:02.148Z"
   },
   {
    "duration": 256,
    "start_time": "2022-08-29T10:16:03.035Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:16:03.293Z"
   },
   {
    "duration": 3607,
    "start_time": "2022-08-29T10:16:03.298Z"
   },
   {
    "duration": 5396,
    "start_time": "2022-08-29T10:16:06.907Z"
   },
   {
    "duration": 31265,
    "start_time": "2022-08-29T10:16:12.305Z"
   },
   {
    "duration": 32,
    "start_time": "2022-08-29T10:16:43.572Z"
   },
   {
    "duration": 12470,
    "start_time": "2022-08-29T10:16:43.606Z"
   },
   {
    "duration": 20922,
    "start_time": "2022-08-29T10:16:56.079Z"
   },
   {
    "duration": 1489,
    "start_time": "2022-08-29T10:17:17.003Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T10:17:18.494Z"
   },
   {
    "duration": 400,
    "start_time": "2022-08-29T10:17:18.501Z"
   },
   {
    "duration": 23137,
    "start_time": "2022-08-29T10:17:18.904Z"
   },
   {
    "duration": 498,
    "start_time": "2022-08-29T10:17:42.042Z"
   },
   {
    "duration": 37382,
    "start_time": "2022-08-29T10:17:42.541Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:18:19.925Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:18:19.926Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:18:19.928Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:18:19.929Z"
   },
   {
    "duration": 1450,
    "start_time": "2022-08-29T10:18:25.132Z"
   },
   {
    "duration": 864,
    "start_time": "2022-08-29T10:18:26.584Z"
   },
   {
    "duration": 254,
    "start_time": "2022-08-29T10:18:27.450Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T10:18:27.707Z"
   },
   {
    "duration": 3573,
    "start_time": "2022-08-29T10:18:27.713Z"
   },
   {
    "duration": 5343,
    "start_time": "2022-08-29T10:18:31.288Z"
   },
   {
    "duration": 31467,
    "start_time": "2022-08-29T10:18:36.632Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-29T10:19:08.100Z"
   },
   {
    "duration": 12529,
    "start_time": "2022-08-29T10:19:08.143Z"
   },
   {
    "duration": 20187,
    "start_time": "2022-08-29T10:19:20.674Z"
   },
   {
    "duration": 1783,
    "start_time": "2022-08-29T10:19:40.862Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:19:42.647Z"
   },
   {
    "duration": 367,
    "start_time": "2022-08-29T10:19:42.652Z"
   },
   {
    "duration": 24627,
    "start_time": "2022-08-29T10:19:43.020Z"
   },
   {
    "duration": 492,
    "start_time": "2022-08-29T10:20:07.649Z"
   },
   {
    "duration": 359105,
    "start_time": "2022-08-29T10:20:08.142Z"
   },
   {
    "duration": 4048,
    "start_time": "2022-08-29T10:26:07.249Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T10:26:11.298Z"
   },
   {
    "duration": 983981,
    "start_time": "2022-08-29T10:26:11.303Z"
   },
   {
    "duration": 7925,
    "start_time": "2022-08-29T10:42:35.286Z"
   },
   {
    "duration": 116,
    "start_time": "2022-08-29T10:43:26.974Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:43:33.106Z"
   },
   {
    "duration": 885,
    "start_time": "2022-08-29T10:44:35.447Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-29T10:45:37.050Z"
   },
   {
    "duration": 147036,
    "start_time": "2022-08-29T10:46:00.015Z"
   },
   {
    "duration": 59707,
    "start_time": "2022-08-29T10:50:30.197Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T10:51:29.906Z"
   },
   {
    "duration": 1370,
    "start_time": "2022-08-29T10:51:33.927Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T10:56:44.376Z"
   },
   {
    "duration": 143998,
    "start_time": "2022-08-29T10:57:05.664Z"
   },
   {
    "duration": 1506,
    "start_time": "2022-08-29T11:00:03.304Z"
   },
   {
    "duration": 63,
    "start_time": "2022-08-29T11:00:14.805Z"
   },
   {
    "duration": 2995,
    "start_time": "2022-08-29T11:00:39.585Z"
   },
   {
    "duration": 502,
    "start_time": "2022-08-29T11:01:06.951Z"
   },
   {
    "duration": 677,
    "start_time": "2022-08-29T11:01:14.652Z"
   },
   {
    "duration": 103050,
    "start_time": "2022-08-29T11:01:33.107Z"
   },
   {
    "duration": 1154,
    "start_time": "2022-08-29T11:03:22.192Z"
   },
   {
    "duration": 143256,
    "start_time": "2022-08-29T11:03:34.830Z"
   },
   {
    "duration": 1544,
    "start_time": "2022-08-29T11:06:51.118Z"
   },
   {
    "duration": 143,
    "start_time": "2022-08-29T11:07:34.514Z"
   },
   {
    "duration": 112726,
    "start_time": "2022-08-29T11:07:48.473Z"
   },
   {
    "duration": 1131,
    "start_time": "2022-08-29T11:16:22.957Z"
   },
   {
    "duration": 104154,
    "start_time": "2022-08-29T11:17:23.756Z"
   },
   {
    "duration": 1158,
    "start_time": "2022-08-29T11:20:52.398Z"
   },
   {
    "duration": 1377,
    "start_time": "2022-08-29T11:22:36.421Z"
   },
   {
    "duration": 877,
    "start_time": "2022-08-29T11:22:44.422Z"
   },
   {
    "duration": 919,
    "start_time": "2022-08-29T11:22:52.430Z"
   },
   {
    "duration": 903,
    "start_time": "2022-08-29T11:23:15.980Z"
   },
   {
    "duration": 894,
    "start_time": "2022-08-29T11:23:26.339Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-29T11:23:57.788Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-29T11:24:39.991Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-29T11:24:56.240Z"
   },
   {
    "duration": 968,
    "start_time": "2022-08-29T11:26:18.505Z"
   },
   {
    "duration": 917,
    "start_time": "2022-08-29T11:26:49.886Z"
   },
   {
    "duration": 926,
    "start_time": "2022-08-29T11:27:52.084Z"
   },
   {
    "duration": 893,
    "start_time": "2022-08-29T11:28:06.355Z"
   },
   {
    "duration": 926,
    "start_time": "2022-08-29T11:29:21.026Z"
   },
   {
    "duration": 64,
    "start_time": "2022-08-29T11:31:59.074Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:37:02.029Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T11:37:12.431Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:37:19.905Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:37:26.459Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:37:37.151Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:37:42.977Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T11:37:51.894Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T11:37:56.411Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T11:38:01.201Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T11:38:04.347Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T11:38:25.647Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:38:33.527Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T11:38:50.724Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:39:09.357Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T11:42:39.484Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-29T11:43:20.408Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T11:44:23.173Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-29T11:45:01.223Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-29T11:45:16.708Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-29T11:45:37.160Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T11:45:49.788Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T11:45:53.060Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T11:46:17.204Z"
   },
   {
    "duration": 463,
    "start_time": "2022-08-29T11:46:57.369Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-29T11:47:04.779Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T11:47:14.915Z"
   },
   {
    "duration": 21,
    "start_time": "2022-08-29T11:47:28.921Z"
   },
   {
    "duration": 21,
    "start_time": "2022-08-29T11:48:14.639Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-29T11:48:31.095Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T11:49:16.243Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-29T11:49:25.885Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T11:49:28.380Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-29T11:49:35.627Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T11:50:00.241Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T11:50:08.031Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-29T11:50:23.081Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T11:50:45.214Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T12:04:54.505Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T12:05:56.254Z"
   },
   {
    "duration": 139,
    "start_time": "2022-08-29T12:06:25.439Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:06:29.237Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:06:41.815Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:06:47.510Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:06:51.299Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:06:56.349Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:07:01.010Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:07:09.126Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:07:41.905Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:07:56.167Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:08:01.055Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:08:11.782Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:08:42.781Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:08:53.787Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:09:01.429Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:09:18.435Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T12:09:33.003Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:09:39.060Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:09:43.703Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-29T12:09:46.074Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:09:49.907Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:10:09.335Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:10:18.498Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:10:27.508Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:10:31.527Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:10:46.544Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:10:50.831Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:10:58.473Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:11:06.098Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:11:12.245Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:11:15.851Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:11:21.918Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:12:59.126Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:14:18.375Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:14:27.442Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:15:04.863Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-29T12:15:12.561Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:15:46.580Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:15:51.738Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:16:06.945Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:16:10.713Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T12:16:14.051Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:16:16.606Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T12:16:29.374Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:16:41.863Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:16:53.840Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T12:20:37.629Z"
   },
   {
    "duration": 8143,
    "start_time": "2022-08-29T12:21:47.862Z"
   },
   {
    "duration": 429,
    "start_time": "2022-08-29T12:23:14.768Z"
   },
   {
    "duration": 8207,
    "start_time": "2022-08-29T12:23:24.739Z"
   },
   {
    "duration": 455,
    "start_time": "2022-08-29T12:23:33.733Z"
   },
   {
    "duration": 8224,
    "start_time": "2022-08-29T12:23:41.455Z"
   },
   {
    "duration": 439,
    "start_time": "2022-08-29T12:23:51.177Z"
   },
   {
    "duration": 261,
    "start_time": "2022-08-29T12:24:19.098Z"
   },
   {
    "duration": 8021,
    "start_time": "2022-08-29T12:24:28.479Z"
   },
   {
    "duration": 8291,
    "start_time": "2022-08-29T12:24:41.837Z"
   },
   {
    "duration": 623,
    "start_time": "2022-08-29T12:24:53.128Z"
   },
   {
    "duration": 329,
    "start_time": "2022-08-29T12:24:55.541Z"
   },
   {
    "duration": 8226,
    "start_time": "2022-08-29T12:25:13.521Z"
   },
   {
    "duration": 592,
    "start_time": "2022-08-29T12:25:21.749Z"
   },
   {
    "duration": 255,
    "start_time": "2022-08-29T12:25:25.423Z"
   },
   {
    "duration": 8602,
    "start_time": "2022-08-29T12:25:40.956Z"
   },
   {
    "duration": 725,
    "start_time": "2022-08-29T12:25:50.232Z"
   },
   {
    "duration": 270,
    "start_time": "2022-08-29T12:25:52.158Z"
   },
   {
    "duration": 8749,
    "start_time": "2022-08-29T12:25:56.882Z"
   },
   {
    "duration": 1043,
    "start_time": "2022-08-29T12:26:06.366Z"
   },
   {
    "duration": 255,
    "start_time": "2022-08-29T12:26:09.994Z"
   },
   {
    "duration": 8420,
    "start_time": "2022-08-29T12:26:19.821Z"
   },
   {
    "duration": 933,
    "start_time": "2022-08-29T12:26:28.849Z"
   },
   {
    "duration": 251,
    "start_time": "2022-08-29T12:26:31.891Z"
   },
   {
    "duration": 14306,
    "start_time": "2022-08-29T12:26:47.020Z"
   },
   {
    "duration": 629,
    "start_time": "2022-08-29T12:27:01.328Z"
   },
   {
    "duration": 262,
    "start_time": "2022-08-29T12:27:01.958Z"
   },
   {
    "duration": 14578,
    "start_time": "2022-08-29T12:27:11.130Z"
   },
   {
    "duration": 740,
    "start_time": "2022-08-29T12:27:25.710Z"
   },
   {
    "duration": 269,
    "start_time": "2022-08-29T12:27:26.452Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T12:28:10.345Z"
   },
   {
    "duration": 14880,
    "start_time": "2022-08-29T12:28:22.481Z"
   },
   {
    "duration": 984,
    "start_time": "2022-08-29T12:28:38.386Z"
   },
   {
    "duration": 253,
    "start_time": "2022-08-29T12:28:41.690Z"
   },
   {
    "duration": 15177,
    "start_time": "2022-08-29T12:28:48.321Z"
   },
   {
    "duration": 724,
    "start_time": "2022-08-29T12:29:03.501Z"
   },
   {
    "duration": 287,
    "start_time": "2022-08-29T12:29:04.226Z"
   },
   {
    "duration": 14379,
    "start_time": "2022-08-29T12:29:20.616Z"
   },
   {
    "duration": 512,
    "start_time": "2022-08-29T12:29:34.996Z"
   },
   {
    "duration": 258,
    "start_time": "2022-08-29T12:29:35.510Z"
   },
   {
    "duration": 14312,
    "start_time": "2022-08-29T12:29:40.848Z"
   },
   {
    "duration": 573,
    "start_time": "2022-08-29T12:29:55.162Z"
   },
   {
    "duration": 263,
    "start_time": "2022-08-29T12:29:55.738Z"
   },
   {
    "duration": 15025,
    "start_time": "2022-08-29T12:30:01.326Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-08-29T12:30:16.353Z"
   },
   {
    "duration": 259,
    "start_time": "2022-08-29T12:30:17.359Z"
   },
   {
    "duration": 14962,
    "start_time": "2022-08-29T12:30:31.916Z"
   },
   {
    "duration": 698,
    "start_time": "2022-08-29T12:30:46.880Z"
   },
   {
    "duration": 263,
    "start_time": "2022-08-29T12:30:47.581Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T12:31:23.633Z"
   },
   {
    "duration": 15343,
    "start_time": "2022-08-29T12:31:25.572Z"
   },
   {
    "duration": 685,
    "start_time": "2022-08-29T12:31:40.917Z"
   },
   {
    "duration": 263,
    "start_time": "2022-08-29T12:31:41.603Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T12:32:14.429Z"
   },
   {
    "duration": 14708,
    "start_time": "2022-08-29T12:35:42.235Z"
   },
   {
    "duration": 11888,
    "start_time": "2022-08-29T12:37:09.842Z"
   },
   {
    "duration": 79069,
    "start_time": "2022-08-29T12:37:22.972Z"
   },
   {
    "duration": 62,
    "start_time": "2022-08-29T12:38:44.400Z"
   },
   {
    "duration": 365,
    "start_time": "2022-08-29T12:39:04.155Z"
   },
   {
    "duration": 287,
    "start_time": "2022-08-29T12:39:25.337Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T12:40:01.768Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T12:40:06.697Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-29T12:40:24.626Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-29T12:40:41.135Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T12:41:32.924Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T12:42:04.231Z"
   },
   {
    "duration": 20,
    "start_time": "2022-08-29T12:42:16.822Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-29T12:42:26.055Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T12:42:38.571Z"
   },
   {
    "duration": 203,
    "start_time": "2022-08-29T12:42:44.189Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-29T12:42:59.175Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T12:43:09.300Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T12:43:13.802Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T12:43:19.798Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-29T12:43:25.187Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-29T12:43:28.749Z"
   },
   {
    "duration": 14742,
    "start_time": "2022-08-29T12:43:41.762Z"
   },
   {
    "duration": 873,
    "start_time": "2022-08-29T12:43:56.506Z"
   },
   {
    "duration": 244,
    "start_time": "2022-08-29T12:43:59.166Z"
   },
   {
    "duration": 14664,
    "start_time": "2022-08-29T12:44:07.145Z"
   },
   {
    "duration": 496,
    "start_time": "2022-08-29T12:44:21.811Z"
   },
   {
    "duration": 246,
    "start_time": "2022-08-29T12:44:23.762Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-29T12:44:34.003Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T12:44:38.866Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:44:41.199Z"
   },
   {
    "duration": 14728,
    "start_time": "2022-08-29T12:44:43.883Z"
   },
   {
    "duration": 626,
    "start_time": "2022-08-29T12:44:58.613Z"
   },
   {
    "duration": 266,
    "start_time": "2022-08-29T12:45:00.391Z"
   },
   {
    "duration": 14435,
    "start_time": "2022-08-29T12:45:24.090Z"
   },
   {
    "duration": 644,
    "start_time": "2022-08-29T12:45:38.527Z"
   },
   {
    "duration": 357,
    "start_time": "2022-08-29T12:45:39.173Z"
   },
   {
    "duration": 14754,
    "start_time": "2022-08-29T12:46:08.937Z"
   },
   {
    "duration": 682,
    "start_time": "2022-08-29T12:46:23.693Z"
   },
   {
    "duration": 262,
    "start_time": "2022-08-29T12:46:24.376Z"
   },
   {
    "duration": 247,
    "start_time": "2022-08-29T12:48:13.424Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T12:48:44.825Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T12:48:54.178Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:49:11.086Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-29T12:49:43.953Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:49:51.360Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T12:49:59.151Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-29T12:50:14.189Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T12:50:24.238Z"
   },
   {
    "duration": 21410,
    "start_time": "2022-08-29T12:50:56.902Z"
   },
   {
    "duration": 724,
    "start_time": "2022-08-29T12:51:18.314Z"
   },
   {
    "duration": 285,
    "start_time": "2022-08-29T12:51:19.040Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T12:51:24.075Z"
   },
   {
    "duration": 14609,
    "start_time": "2022-08-29T12:51:44.817Z"
   },
   {
    "duration": 674,
    "start_time": "2022-08-29T12:51:59.429Z"
   },
   {
    "duration": 258,
    "start_time": "2022-08-29T12:52:00.104Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-29T12:56:19.097Z"
   },
   {
    "duration": 254,
    "start_time": "2022-08-29T12:56:22.364Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-29T12:56:24.712Z"
   },
   {
    "duration": 1591,
    "start_time": "2022-08-29T13:01:20.593Z"
   },
   {
    "duration": 871,
    "start_time": "2022-08-29T13:01:22.186Z"
   },
   {
    "duration": 256,
    "start_time": "2022-08-29T13:01:23.059Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T13:01:23.317Z"
   },
   {
    "duration": 3567,
    "start_time": "2022-08-29T13:01:23.323Z"
   },
   {
    "duration": 5394,
    "start_time": "2022-08-29T13:01:26.892Z"
   },
   {
    "duration": 31256,
    "start_time": "2022-08-29T13:01:32.288Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-29T13:02:03.546Z"
   },
   {
    "duration": 12546,
    "start_time": "2022-08-29T13:02:03.584Z"
   },
   {
    "duration": 20354,
    "start_time": "2022-08-29T13:02:16.132Z"
   },
   {
    "duration": 1607,
    "start_time": "2022-08-29T13:02:36.488Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T13:02:38.097Z"
   },
   {
    "duration": 263,
    "start_time": "2022-08-29T13:02:38.103Z"
   },
   {
    "duration": 24277,
    "start_time": "2022-08-29T13:02:38.368Z"
   },
   {
    "duration": 361,
    "start_time": "2022-08-29T13:03:02.649Z"
   },
   {
    "duration": 351291,
    "start_time": "2022-08-29T13:03:03.012Z"
   },
   {
    "duration": 359,
    "start_time": "2022-08-29T13:08:54.305Z"
   },
   {
    "duration": 124,
    "start_time": "2022-08-29T13:08:54.666Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.792Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.793Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.794Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.795Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.796Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.797Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.798Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.799Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T13:08:54.800Z"
   },
   {
    "duration": 1,
    "start_time": "2022-08-29T13:08:54.801Z"
   },
   {
    "duration": 1489,
    "start_time": "2022-08-29T14:42:16.216Z"
   },
   {
    "duration": 891,
    "start_time": "2022-08-29T14:42:17.707Z"
   },
   {
    "duration": 264,
    "start_time": "2022-08-29T14:42:18.600Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-29T14:42:18.866Z"
   },
   {
    "duration": 3649,
    "start_time": "2022-08-29T14:42:18.886Z"
   },
   {
    "duration": 5572,
    "start_time": "2022-08-29T14:42:22.537Z"
   },
   {
    "duration": 32948,
    "start_time": "2022-08-29T14:42:28.110Z"
   },
   {
    "duration": 37,
    "start_time": "2022-08-29T14:43:01.060Z"
   },
   {
    "duration": 13388,
    "start_time": "2022-08-29T14:43:01.099Z"
   },
   {
    "duration": 21203,
    "start_time": "2022-08-29T14:43:14.490Z"
   },
   {
    "duration": 1753,
    "start_time": "2022-08-29T14:43:35.695Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-29T14:43:37.450Z"
   },
   {
    "duration": 277,
    "start_time": "2022-08-29T14:43:37.455Z"
   },
   {
    "duration": 26214,
    "start_time": "2022-08-29T14:43:37.733Z"
   },
   {
    "duration": 349,
    "start_time": "2022-08-29T14:44:03.949Z"
   },
   {
    "duration": 361636,
    "start_time": "2022-08-29T14:44:04.300Z"
   },
   {
    "duration": 364,
    "start_time": "2022-08-29T14:50:05.939Z"
   },
   {
    "duration": 1589,
    "start_time": "2022-08-29T14:55:29.493Z"
   },
   {
    "duration": 957,
    "start_time": "2022-08-29T14:55:31.084Z"
   },
   {
    "duration": 285,
    "start_time": "2022-08-29T14:55:32.043Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-29T14:55:32.331Z"
   },
   {
    "duration": 3900,
    "start_time": "2022-08-29T14:55:32.343Z"
   },
   {
    "duration": 6007,
    "start_time": "2022-08-29T14:55:36.245Z"
   },
   {
    "duration": 34207,
    "start_time": "2022-08-29T14:55:42.254Z"
   },
   {
    "duration": 53,
    "start_time": "2022-08-29T14:56:16.462Z"
   },
   {
    "duration": 13608,
    "start_time": "2022-08-29T14:56:16.518Z"
   },
   {
    "duration": 22344,
    "start_time": "2022-08-29T14:56:30.129Z"
   },
   {
    "duration": 1794,
    "start_time": "2022-08-29T14:56:52.476Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T14:56:54.272Z"
   },
   {
    "duration": 292,
    "start_time": "2022-08-29T14:56:54.279Z"
   },
   {
    "duration": 21565,
    "start_time": "2022-08-29T14:56:54.573Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.141Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.142Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.143Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.144Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.145Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.147Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.148Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.150Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.152Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.154Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.156Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.157Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.158Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T14:57:16.159Z"
   },
   {
    "duration": 1506,
    "start_time": "2022-08-29T14:57:20.797Z"
   },
   {
    "duration": 908,
    "start_time": "2022-08-29T14:57:22.305Z"
   },
   {
    "duration": 268,
    "start_time": "2022-08-29T14:57:23.215Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-29T14:57:23.486Z"
   },
   {
    "duration": 3785,
    "start_time": "2022-08-29T14:57:23.494Z"
   },
   {
    "duration": 5573,
    "start_time": "2022-08-29T14:57:27.280Z"
   },
   {
    "duration": 34345,
    "start_time": "2022-08-29T14:57:32.855Z"
   },
   {
    "duration": 65,
    "start_time": "2022-08-29T14:58:07.201Z"
   },
   {
    "duration": 13699,
    "start_time": "2022-08-29T14:58:07.268Z"
   },
   {
    "duration": 21771,
    "start_time": "2022-08-29T14:58:20.969Z"
   },
   {
    "duration": 1827,
    "start_time": "2022-08-29T14:58:42.742Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-29T14:58:44.571Z"
   },
   {
    "duration": 314,
    "start_time": "2022-08-29T14:58:44.577Z"
   },
   {
    "duration": 30855,
    "start_time": "2022-08-29T14:58:44.893Z"
   },
   {
    "duration": 313,
    "start_time": "2022-08-29T14:59:15.750Z"
   },
   {
    "duration": 363975,
    "start_time": "2022-08-29T14:59:16.065Z"
   },
   {
    "duration": 343,
    "start_time": "2022-08-29T15:05:20.041Z"
   },
   {
    "duration": 145308,
    "start_time": "2022-08-29T15:05:20.386Z"
   },
   {
    "duration": 1418,
    "start_time": "2022-08-29T15:07:45.696Z"
   },
   {
    "duration": 1152,
    "start_time": "2022-08-29T15:07:47.116Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-29T15:07:48.270Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-29T15:07:48.275Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-29T15:07:48.305Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-29T15:07:48.313Z"
   },
   {
    "duration": 14523,
    "start_time": "2022-08-29T15:07:48.326Z"
   },
   {
    "duration": 712,
    "start_time": "2022-08-29T15:08:02.851Z"
   },
   {
    "duration": 125,
    "start_time": "2022-08-29T15:08:03.565Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-29T15:08:03.692Z"
   },
   {
    "duration": 268,
    "start_time": "2022-08-29T16:16:36.431Z"
   },
   {
    "duration": 23,
    "start_time": "2022-08-29T16:16:41.204Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
